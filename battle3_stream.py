#!/usr/bin/env python3
# coding: utf-8

# æœ¬è„šæœ¬é€‚ç”¨äºŽpytho3.10åŠä»¥ä¸Š
# requestså’Œjsonæ˜¯æœ¬è„šæœ¬çš„ä¾èµ–ï¼Œéœ€è¦å®‰è£…
import requests
import json
import streamlit as st
import time

st.set_page_config(layout="wide", page_title="æ¨¡åž‹ç«žæŠ€")
st.title("Med-Eval æ¨¡åž‹ç«žæŠ€")

model_urls = {
    'AiMed': 'http://192.168.0.155:8000/v1/chat/completions',
    'Doctor': 'http://192.168.0.118:8088/base',
    'GPT4': 'http://192.168.0.118:2223/v1/chat/completions'
}

header = {
    'Content-Type': 'application/json'
}
data = {
    'model': "AiMed",
    'stream': True,
    'temperature': 1
}

# æ¸…ç©ºå¯¹è¯
def clear_chat_history():
    del st.session_state.messages

# å‘é€è¯·æ±‚å¹¶èŽ·å–å“åº”
def get_response(url, messages):
    data["messages"] = messages
    response = requests.post(url, headers=header, json=data, stream=True)
    answer = ""

    print("----------------debug-------------------")
    print("url:{}".format(url))
    print("data:{}".format(data))
    print("response:{}".format(response.status_code))
    print("time:{}".format(time.strftime('%m-%d %H:%M:%S', time.localtime(time.time()))))


    for chunk in response.iter_content(chunk_size=1024):
        str_obj = chunk.decode('utf-8').replace('data: ', '').strip()
        json_obj = json.loads(str_obj)
        if 'content' in json_obj['choices'][0]['delta'].keys():
            answer += json_obj['choices'][0]['delta']['content']

    print("answer:{}".format(answer))
    print("---------------------------------------")

    return answer

# æ˜¾ç¤ºå¯¹è¯åŽ†å²
def display_chat_history(model, role, content):
    avatar='ðŸ§‘â€ðŸ’»' if role == "user" else 'ðŸ¤–'
    with st.chat_message(role, avatar=avatar):
        st.markdown(content)

def main():
    with st.chat_message("assistant", avatar='ðŸ¤–'):
        st.markdown("æ‚¨å¥½ï¼Œè¿™é‡Œæ˜¯Med-Evalç«žæŠ€åœºï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ðŸ¥°")

    # ä½¿ç”¨columnsæ¥å¹¶æŽ’æ˜¾ç¤º
    col1, col2 = st.columns(2)
    # åœ¨ç¬¬ä¸€ä¸ªåˆ—ä¸­è®¾ç½®ç«žæŠ€æ¨¡åž‹æ•°é‡
    with col1:
        # è®¾ç½®ç«žæŠ€æ¨¡åž‹æ•°é‡
        n = st.number_input('æ¨¡åž‹æ•°é‡', min_value=1, max_value=12, value=3)
    # åœ¨ç¬¬äºŒä¸ªåˆ—ä¸­é€‰æ‹©ç«žæŠ€é¡¹ç›®
    with col2:
        # ç«žæŠ€é¡¹ç›®é€‰æ‹©
        competiton_types = ['ç”¨æˆ·äº¤äº’', 'N+åŒ»ç–—åœºæ™¯', 'Med-Evalæµ‹è¯„', 'å…¶å®ƒæµ‹è¯„']
        competition_type = st.selectbox('ç«žæŠ€é¡¹ç›®', competiton_types)

    # ç«žæŠ€æ¨¡åž‹é€‰æ‹©
    models = model_urls.keys()  # ç¤ºä¾‹æ¨¡åž‹åˆ—è¡¨
    selected_models = []  # å­˜å‚¨é€‰æ‹©çš„æ¨¡åž‹

    single_row_num = 3 if n > 2 else n
    for i in range(0, n, single_row_num):
        cols = st.columns(single_row_num)
        for j in range(single_row_num):
            if i + j < n:
                with cols[j]:
                    # å­˜å‚¨æ¯ä¸ªæ¨¡åž‹é€‰æ‹©å™¨çš„å€¼
                    selected_model = st.selectbox(f'é€‰æ‹©æ¨¡åž‹{i + j + 1}', models)
                    selected_models.append(selected_model)

    if competition_type == 'ç”¨æˆ·äº¤äº’':

        if n == 1:
            if "messages" not in st.session_state:
                st.session_state["messages"] = []
            else:
                for message in st.session_state.messages:
                    avatar = 'ðŸ§‘â€ðŸ’»' if message["role"] == "user" else 'ðŸ¤–'
                    with st.chat_message(message["role"], avatar=avatar):
                        st.markdown(message["content"])
            messages = st.session_state["messages"]

            if prompt := st.chat_input("Shift + Enter æ¢è¡Œ, Enter å‘é€"):
                with st.chat_message("user", avatar='ðŸ§‘â€ðŸ’»'):
                    st.markdown(prompt)

                messages.append({"role": "user", "content": prompt})

                st.header(selected_models[0])
                with st.chat_message("assistant", avatar='ðŸ¤–'):
                    placeholder = st.empty()

                    data["messages"] = messages
                    response = requests.post(model_urls[selected_models[0]], headers=header, json=data, stream=True)
                    answer = ""
                    for chunk in response.iter_content(chunk_size=1024):  # æ³¨æ„chunkæ˜¯bytesç±»åž‹ï¼Œéœ€è¦å…ˆè½¬æ¢
                        # å¤„ç†å“åº”å†…å®¹
                        # å°†bytesç±»åž‹è½¬æ¢ä¸ºå­—ç¬¦ä¸²ç±»åž‹
                        str_obj = chunk.decode('utf-8')
                        str_obj = str_obj.replace('data: ', '').strip()
                        # å°†å­—ç¬¦ä¸²ç±»åž‹è½¬æ¢ä¸ºjsonæ ¼å¼
                        json_obj = json.loads(str_obj)

                        if 'content' in json_obj['choices'][0]['delta'].keys():
                            answer = answer + json_obj['choices'][0]['delta']['content']
                            placeholder.markdown(answer)
                    messages.append({"role": "assistant", "content": answer})
            # ç«žæŠ€ç»“æžœè¯„ä»·
            # åˆ›å»ºä¸‰ä¸ªå¹¶æŽ’çš„åˆ—
            clear, good, bad = st.columns(3)
            with good:
                if st.button('å¥½', key='good', help='ç‚¹å‡»æ­¤æŒ‰é’®è¡¨ç¤ºå¥½çš„è¯„ä»·'):
                    st.write('ç”¨æˆ·è¯„ä»·ï¼šå¥½')
            with bad:
                if st.button('å', key='bad', help='ç‚¹å‡»æ­¤æŒ‰é’®è¡¨ç¤ºåçš„è¯„ä»·'):
                    st.write('ç”¨æˆ·è¯„ä»·ï¼šå')
            with clear:
                st.button("æ¸…ç©ºå¯¹è¯", on_click=clear_chat_history)

        else:
            # ä¸ºæ¯ä¸ªé€‰ä¸­çš„æ¨¡åž‹åˆå§‹åŒ–å¯¹è¯åŽ†å²ï¼ŒåŒæ—¶ä¸ºåŒåæ¨¡åž‹æ·»åŠ åºå·
            model_instances = {}
            model_names = []
            for model in selected_models:
                model_instances[model] = model_instances.get(model, 0) + 1
                model_name_with_index = f"{model}_{model_instances[model]}"
                model_names.append(model_name_with_index)
                # åˆå§‹åŒ–session
                if model_name_with_index not in st.session_state:
                    st.session_state[model_name_with_index] = []

            # å¤„ç†ç”¨æˆ·è¾“å…¥
            if prompt := st.chat_input("Shift + Enter æ¢è¡Œ, Enter å‘é€"):
                # æ˜¾ç¤ºç”¨æˆ·è¾“å…¥
                with st.chat_message("user", avatar='ðŸ§‘â€ðŸ’»'):
                    st.markdown(prompt)

                # åˆ›å»ºæ¨¡åž‹å“åº”çš„åˆ—
                row_columns = []
                show_line = 3 if n > 2 else n
                for idx, model_name_with_index in enumerate(model_names):
                    if idx % show_line == 0:
                        row_columns = st.columns(show_line)
                    column_idx = idx % show_line
                    with row_columns[column_idx]:
                        st.header(model_name_with_index)

                        st.session_state[model_name_with_index].append({"role": "user", "content": prompt})

                        parts = model_name_with_index.rsplit('_', 1)
                        model = parts[0] if len(parts) == 2 else model_name_with_index

                        answer = get_response(model_urls[model], st.session_state[model_name_with_index])
                        st.session_state[model_name_with_index].append({"role": "assistant", "content": answer})

                        with st.chat_message("assistant", avatar='ðŸ¤–'):
                            st.markdown(answer)

                # æ¨¡åž‹è¯„ä»·
                models_judges = []  # å­˜å‚¨é€‰æ‹©çš„æ¨¡åž‹

                single_row_num = 3 if n > 2 else n
                for i in range(0, n, single_row_num):
                    cols = st.columns(single_row_num)
                    for j in range(single_row_num):
                        if i + j < n:
                            with cols[j]:
                                # å­˜å‚¨æ¯ä¸ªæ¨¡åž‹é€‰æ‹©å™¨çš„å€¼
                                models_judge = st.selectbox(f'æŽ’åç¬¬{i + j + 1}', model_names)
                                models_judges.append(models_judge)



if __name__ == "__main__":
    main()
